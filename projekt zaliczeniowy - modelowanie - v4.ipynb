{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 2 - modelowanie\n",
    "\n",
    "#### kolejne kroki:\n",
    "- pobranie danych do modelowania\n",
    "- przygotowanie zestawów danych train-test w kilku wariantach\n",
    "- modelowanie z zastosowaniem wybranych klasyfikatorów\n",
    "- omówienie i podsumowanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I Przygotowanie danych do modelowania\n",
    "\n",
    "#### Import danych\n",
    "\n",
    "Dane do modelowania przygotowane zostały w 4 wersjach - wersje te różnią się sposobem uzupełnienia brakujących wartości w zakresie 5 zmiennych:\n",
    "\n",
    "- 'offer_amount', \n",
    "- 'offer_period', \n",
    "- 'interest_rate', \n",
    "- 'fee', \n",
    "- 'offer_monthly_obligation'.\n",
    "\n",
    "Są to następujące warianty:\n",
    "\n",
    "- 1 - zmienne usunięte ze zbioru danych,\n",
    "- 2 - braki danych uzupełnione medianą,\n",
    "- 3 - braki danych uzupełnione przez losowanie z rozkładu normalnego,\n",
    "- 4 - braki danych uzupełnione przez kopiowanie danych z innych rekordów datasetu.\n",
    "\n",
    "Przygotowanie modelu wykonywane będzie dla każdego z wariantów niezależnie.\n",
    "Sposób uzupełnienia wartości brakujacych zostanie oceniony po analizie jakości uzyskanych modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import danych\n",
    "col_names = ['ID', 'gender', 'city', 'income', 'birth_date', 'application_date', 'requested_amount', \n",
    "             'requested_period', 'financial_obligations', 'employer_name', 'account_bank', \n",
    "             'mobile_verification_flag', 'var_5', 'var_1', 'offer_amount', 'offer_period', 'interest_rate', \n",
    "             'fee', 'offer_monthly_obligation', 'filled_form_flag', 'device', 'var_2', 'source', 'var_4', \n",
    "             'disbursed_flag', 'latitude', 'longitude', 'age']\n",
    "\n",
    "datasets = {\n",
    "    1:{'name':'none'},\n",
    "    2:{'name':'median'},\n",
    "    3:{'name':'distribution'},\n",
    "    4:{'name':'observation'}\n",
    "}\n",
    "\n",
    "datasets[2]['data'] = pd.read_csv('dataset_inputation_median.csv', delimiter = ';', engine='python', header = None, names = col_names, \n",
    "                      index_col = 0, skiprows = 1 )\n",
    "datasets[3]['data'] = pd.read_csv('dataset_inputation_distribution.csv', delimiter = ';', engine='python', header = None, names = col_names, \n",
    "                      index_col = 0, skiprows = 1 )\n",
    "datasets[4]['data'] = pd.read_csv('dataset_inputation_random_observation.csv', delimiter = ';', engine='python', header = None, names = col_names, \n",
    "                      index_col = 0, skiprows = 1 )\n",
    "datasets[1]['data'] = datasets[2]['data'].copy()\n",
    "\n",
    "columns_to_drop = ['city', 'birth_date', 'application_date', 'employer_name', 'account_bank']\n",
    "columns_to_rename = {'ID':'id', \n",
    "                     'gender':'cat01', \n",
    "                     'income':'num01', \n",
    "                     'requested_amount':'num02', \n",
    "                     'requested_period':'num03',\n",
    "                     'financial_obligations':'num04',\n",
    "                     'mobile_verification_flag':'cat02',\n",
    "                     'var_5':'cat03',\n",
    "                     'var_1':'cat04',\n",
    "                     'offer_amount':'num05',\n",
    "                     'offer_period':'num06',\n",
    "                     'interest_rate':'num07',\n",
    "                     'fee':'num08',\n",
    "                     'offer_monthly_obligation':'num09',\n",
    "                     'filled_form_flag':'cat05',\n",
    "                     'device':'cat06',\n",
    "                     'var_2':'cat07',\n",
    "                     'source':'cat08',\n",
    "                     'var_4':'cat09',\n",
    "                     'disbursed_flag':'explained',\n",
    "                     'latitude':'num10',\n",
    "                     'longitude':'num11',\n",
    "                     'age':'num12'\n",
    "}\n",
    "\n",
    "for item in datasets:\n",
    "    datasets[item]['data'] = datasets[item]['data'].drop(columns_to_drop, axis=1).rename(columns=columns_to_rename)\n",
    "\n",
    "datasets[1]['data'] = datasets[1]['data'].drop(['num05','num06','num07','num08','num09'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podział train-test\n",
    "\n",
    "Dla każdego wariantu danych dzielę dataset na zbiór trenujacy i testowy wg proporcji 3:1.\n",
    "Klasa pozytywnych obserwacji zmiennej objaśnianej jest mało liczna, dlatego żeby zachować proporcjonalny podział\n",
    "stosuję opcję 'stratifiy'. \n",
    "\n",
    "Mała liczność obserwacji pozytywnych w zmiennej objaśnianej będzie wymagać zastosowania skalowania w procesie modelowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "licznosc_zbioru = 87020\n",
      "liczność obserwacji pozytywnych dla zmiennej objaśnianej = 1273.0\n",
      "udział obserwacji pozytywnych zmiennej objaśnianej w zbiorze = 0.01462882096069869\n",
      "\n",
      "Dataset 1: train - 0.014632651497739983 'jedynek', test - 0.01461732934957481 'jedynek'\n",
      "Dataset 2: train - 0.014632651497739983 'jedynek', test - 0.01461732934957481 'jedynek'\n",
      "Dataset 3: train - 0.014632651497739983 'jedynek', test - 0.01461732934957481 'jedynek'\n",
      "Dataset 4: train - 0.014632651497739983 'jedynek', test - 0.01461732934957481 'jedynek'\n"
     ]
    }
   ],
   "source": [
    "licznosc = datasets[1]['data'].shape[0]\n",
    "licznosc_y = sum(datasets[1]['data']['explained'])\n",
    "licznosc_y_procent = licznosc_y / licznosc\n",
    "print(f\"licznosc_zbioru = {licznosc}\")\n",
    "print(f\"liczność obserwacji pozytywnych dla zmiennej objaśnianej = {licznosc_y}\")\n",
    "print(f\"udział obserwacji pozytywnych zmiennej objaśnianej w zbiorze = {licznosc_y_procent}\\n\")\n",
    "      \n",
    "# Train - test split\n",
    "train_test_split_ratio = 0.25\n",
    "\n",
    "for item in datasets:\n",
    "    datasets[item]['X'] = datasets[item]['data'].drop(['explained'], axis=1)\n",
    "    datasets[item]['y'] = datasets[item]['data']['explained']\n",
    "    datasets[item]['X_train'], datasets[item]['X_test'], datasets[item]['y_train'], datasets[item]['y_test'] = train_test_split(datasets[item]['X'], datasets[item]['y'], test_size=train_test_split_ratio, random_state=42, stratify=datasets[item]['y'])\n",
    "    y_train_share = sum(datasets[item]['y_train'])/datasets[item]['X_train'].shape[0]\n",
    "    y_test_share  = sum(datasets[item]['y_test']) /datasets[item]['X_test'].shape[0]\n",
    "    print(f\"Dataset {item}: train - {y_train_share} 'jedynek', test - {y_test_share} 'jedynek'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podejście do zmiennych kategorycznych\n",
    "\n",
    "Na etapie przygotowania danych zmienne kategoryczne zostały zakodowane wg rosnącego udziału obserwacji pozytywnych w danej klasie. Bardziej adekwatne podejście (szczególnie w celu zastosowania regresji logistycznej) jest zastosowanie współczynników WOE (Weight Of Evidence), czyli skalowanie wg proporcji ln(liczba obserwacji pozytywnych / liczba obserwacji negatywnych). \n",
    "\n",
    "Dla każdego ze zbiorów danych wyznaczam wagi WOE do zmiany kodowania zmiennych kategorycznych. Do wyliczenia wag wykorzystuję wyłącznie obserwacje ze zbioru treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# WOE calculation for categorical\n",
    "categorical_variables = [name for name in datasets[1]['data'].columns if 'cat' in name]\n",
    "\n",
    "for item in datasets:\n",
    "    WOE_dataset = datasets[item]['X_train'][categorical_variables]\n",
    "    WOE_dataset['positive'] = datasets[item]['y_train']\n",
    "    WOE_dataset['negative'] = WOE_dataset.apply(lambda x: 1 - x['positive'], axis=1)\n",
    "    WOE_mapper = pd.DataFrame(columns=['feature_name', 'feature_code', 'WOE'])\n",
    "    for variable in categorical_variables:\n",
    "        variable_data = WOE_dataset[[variable, 'positive', 'negative']]\n",
    "        out = variable_data.groupby([variable]).sum()\n",
    "        out['WOE'] = out.apply(lambda x: log(x['positive'] / x['negative']) if x['positive'] > 0 and x['negative'] > 0 else -12, axis = 1)\n",
    "        out['feature_name'] = variable\n",
    "        out['feature_code'] = out.index\n",
    "        out = out[['feature_name', 'feature_code', 'WOE']].reset_index(drop=True)\n",
    "        WOE_mapper = pd.concat([WOE_mapper, out])\n",
    "    datasets[item]['WOE_mapper'] = WOE_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodowanie stosuję zarówno do zbioru treningowego, jak i testowego. Wariant danych z kodowaniem WOE oznaczam odrębnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with WOE\n",
    "\n",
    "def WOE_mapping(dataset, WOE_mapper):\n",
    "    output = dataset.copy()\n",
    "    for variable in categorical_variables:\n",
    "        mapper = WOE_mapper[WOE_mapper['feature_name'] == variable]\n",
    "        mapper_dict = {}\n",
    "        for category in mapper.index:\n",
    "            mapper_dict[mapper.loc[category]['feature_code']] = mapper.loc[category]['WOE']\n",
    "        output[variable] = output.apply(lambda x: mapper_dict[x[variable]], axis=1)\n",
    "    return output\n",
    "\n",
    "for item in datasets:\n",
    "    datasets[item]['X_train_woe'] = WOE_mapping(datasets[item]['X_train'], datasets[item]['WOE_mapper'])\n",
    "    datasets[item]['X_test_woe'] = WOE_mapping(datasets[item]['X_test'], datasets[item]['WOE_mapper'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standaryzacja\n",
    "\n",
    "Dane numeryczne w zbiorze danych są różnorodnie skalowane - np. wiek klienta to zmienna z przedziału ok. [0, 100], tymczasem kwota dochodu - już sięga milionów (dochód wyrażony jest w rupiach indyjskich). Zniwelowanie różnic w skali umożliwia zastosowanie standaryzacji zmiennych - stosuję do tego celu wbudowaną funkcjonalność StandardScaler(). \n",
    "\n",
    "Standaryzacji poddaję zarówno zbiory ze zwyczajnym kodowaniem zmiennych kategorycznych, jak i z kodowaniem WOE.\n",
    "Zbiory przeskalowane oznaczam odrębnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# data scaled\n",
    "for item in datasets:\n",
    "    datasets[item]['scaler'] = StandardScaler()\n",
    "    datasets[item]['WOE_scaler'] = StandardScaler()\n",
    "    datasets[item]['scaler'].fit(datasets[item]['X_train'])\n",
    "    datasets[item]['WOE_scaler'].fit(datasets[item]['X_train_woe'])\n",
    "    datasets[item]['X_train_scaled'] = datasets[item]['scaler'].transform(datasets[item]['X_train'])\n",
    "    datasets[item]['X_test_scaled'] = datasets[item]['scaler'].transform(datasets[item]['X_test'])\n",
    "    datasets[item]['X_train_woe_scaled'] = datasets[item]['WOE_scaler'].transform(datasets[item]['X_train_woe'])\n",
    "    datasets[item]['X_test_woe_scaled'] = datasets[item]['WOE_scaler'].transform(datasets[item]['X_test_woe'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redukcja wymiarowości\n",
    "\n",
    "Korelacja części zmiennych datasetu ze zmienną objaśnianą może być na tyle niska, że zmienna nie wniesie znaczącego udziału w jakość modelu. Redukcja wymiarowości umozliwia wyłuskanie najistotniejszych zmiennych do budowy modelu. Ograniczenie ilości danych usprawnia proces modelowania kosztem niewielkiej straty jakości modelu. Ma to szczególne znaczenie dla zbiorów ze sporą ilością zmiennych modelowych.\n",
    "\n",
    "W naszym przypadku redukcja wymiarowości nie jest konieczna z uwagi na niedużą liczbę zmiennych modleowych (poniżej 20). Mimo to wyznaczam zbiór danych z odcięciem części zmiennych - warunkiem jest obniżenie wyjaśnianej wariancji maksymalnie o 5%. Wykorzystuję Principal Component Analysis (jest dostępna wbudowana funkcjonalność w bibliotece sklearn).\n",
    "\n",
    "Procedurze PCA poddaje się zbiory po regularyzacji, wyliczenie stosuję zarówno do zbioru ze zwyczajnym kodowaniem zmiennych kategorycznych, jak i z kodowaniem WOE. Wersje danych po procedurze PCA odłożone są w osobnych zbiorach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: liczba zmiennych przed PCA: 16, liczba zmiennych po PCA: 13\n",
      "Dataset 2: liczba zmiennych przed PCA: 21, liczba zmiennych po PCA: 16\n",
      "Dataset 3: liczba zmiennych przed PCA: 21, liczba zmiennych po PCA: 17\n",
      "Dataset 4: liczba zmiennych przed PCA: 21, liczba zmiennych po PCA: 17\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "\n",
    "expected_explained_variance_ratio = 0.95\n",
    "\n",
    "def pca_model(dataset):\n",
    "    pca = PCA(random_state=42)\n",
    "    pca.fit(dataset)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    counter = 0\n",
    "    explained_variance_cumulative = 0\n",
    "    for variance in explained_variance:\n",
    "        if explained_variance_cumulative <= expected_explained_variance_ratio:\n",
    "            explained_variance_cumulative += variance\n",
    "            counter += 1\n",
    "    pca = PCA(random_state=42, n_components = counter)\n",
    "    pca.fit(dataset)\n",
    "    return pca\n",
    "\n",
    "for item in datasets:\n",
    "    datasets[item]['PCA'] = pca_model(datasets[item]['X_train_scaled'])\n",
    "    datasets[item]['WOE_PCA'] = pca_model(datasets[item]['X_train_woe_scaled'])\n",
    "    datasets[item]['X_train_pca'] = datasets[item]['PCA'].transform(datasets[item]['X_train_scaled'])\n",
    "    datasets[item]['X_test_pca'] = datasets[item]['PCA'].transform(datasets[item]['X_test_scaled'])\n",
    "    datasets[item]['X_train_woe_pca'] = datasets[item]['WOE_PCA'].transform(datasets[item]['X_train_woe_scaled'])\n",
    "    datasets[item]['X_test_woe_pca'] = datasets[item]['WOE_PCA'].transform(datasets[item]['X_test_woe_scaled'])\n",
    "    print(f\"Dataset {item}: liczba zmiennych przed PCA: {datasets[item]['X_train'].shape[1]}, liczba zmiennych po PCA: {datasets[item]['X_train_pca'].shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podumowując - mamy 4 zbiory danych:\n",
    "\n",
    "    - 1 - usunięte zmienne z brakami,\n",
    "    - 2 - braki uzupełnione medianą,\n",
    "    - 3 - braki uzupełnione przez losowanie z rozkładu normalnego,\n",
    "    - 4 - braki uzupełnione przez kopiowanie danych z innych rekordów datasetu,\n",
    "\n",
    "    każdy zbiór w 6 wersjach:\n",
    "    \n",
    "    - bez skalowania, bez WOE,\n",
    "    - bez skalowania, z WOE,\n",
    "    - ze skalowaniem, bez WOE, bez PCA,\n",
    "    - ze skalowaniem, z WOE, bez PCA,\n",
    "    - ze skalowaniem, bez WOE, z PCA,\n",
    "    - ze skalowaniem, z WOE, z PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Modelowanie\n",
    "\n",
    "W modelowaniu przyjąłem następujacy schemat działania - dla danego klasyfikatora:\n",
    "    \n",
    "- zdefiniowanie zakresu parametrów klasyfikatora oraz zakresu wariantów danych do modelowania,\n",
    "- optymalizacja parametrów klasyfikatora z zastosowaniem Grid Search + Cross Validation,\n",
    "- wybór najlepszych zestawów parametrów,\n",
    "- powtórzenie modelowania na wybranych zestawach parametrów na pełnym zbiorze treningowym,\n",
    "- ocena wyników modeli - zestawienie miar dla zbioru testowego i treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja zwracająca miary jakości modelu dla zadanego modelu oraz zbioru zmiennych modelowych i obserwacji\n",
    "def get_measures(model, X, y):\n",
    "    y_predict = model.predict(X)\n",
    "    confusion = metrics.confusion_matrix(y, y_predict)\n",
    "    out = {}\n",
    "    out['accuracy'] = metrics.accuracy_score(y_predict, y)\n",
    "    out['precision'] = metrics.precision_score(y_predict, y)\n",
    "    out['recall'] = metrics.recall_score(y_predict, y)\n",
    "    out['f1'] = metrics.f1_score(y_predict, y)\n",
    "    out['auc'] = metrics.roc_auc_score(y, y_predict)\n",
    "    out['TP'] = confusion[1][1]\n",
    "    out['FP'] = confusion[1][0]\n",
    "    out['TN'] = confusion[0][0]\n",
    "    out['FN'] = confusion[0][1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja realizująca procedurę Grid Search + Cross Validation\n",
    "def model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=4, n_jobs=7, verbose = 1):\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=cv, scoring=scoring, n_jobs=n_jobs, verbose = verbose, refit=True)\n",
    "    grid_search.fit(X, y)\n",
    "    with open(prefix + '_grid_search.pickle', 'wb') as file:\n",
    "        pickle.dump(grid_search, file)\n",
    "    params_list =  ['param_'+x for x in param_grid]\n",
    "    params_list += ['params', 'mean_train_score', 'mean_test_score'] \n",
    "    result = pd.DataFrame(grid_search.cv_results_)[params_list]\n",
    "    result.to_csv(prefix + \".csv\", index=False, sep=';')\n",
    "    return grid_search, result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresja logistyczna\n",
    "\n",
    "Pierwszym stosowanym klasyfikatorem jest regresja logistczna.\n",
    "W procedurze Grid Search sprawdzane będą dwa parametry:\n",
    " \n",
    "- parametr C - parametr sterujący regularyzacją,\n",
    "- parametr 'class_weight' - parametr sterujący przeważaniem zmiennej objaśnianej.\n",
    "\n",
    "Konieczność zastosowania przeważania obserwacji pozytywnych dla zmiennej objaśnianej wynika z bardzo małego udzuału tych obserwacji w analizowanym zbiorze danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - pierwszy przebieg\n",
    "\n",
    "# klasyfikator, zestaw przeszukiwanych parametrów klasyfikatora\n",
    "\n",
    "classifier = LogisticRegression(C = 1.0, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "C = [10**c for c in range(1, 12, 2)]\n",
    "weights = [1, 50, 100, 200]\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "param_grid = {'C': C, 'class_weight': class_weight}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warianty danych badane per każdy dataset\n",
    "data_variants = ['', '_pca', '_scaled', '_woe', '_woe_scaled', '_woe_pca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przebieg Grid Search:\n",
    "\n",
    "- per każdy dataset (4 wersje),\n",
    "- per każdy sposób przygotowania danych (6 wersji),\n",
    "- z optymalizacją miar: AUC / F-score.\n",
    "\n",
    "Z uwagi na czasochłonnośc przeliczenia wynik każdego przebiegu podlega serializacji i zapisowi na dysk, \n",
    "dodatkowo zbierane są średnie miary uzyskane w procedurze Cross Validation dla danego zestawu parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'scoring', 'param_C', 'param_class_weight', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for scoring in ['roc_auc', 'f1']:\n",
    "            prefix = 'logistic_regression_' + str(dataset) + '_' + data_variant + '_' + scoring\n",
    "            print(\"start: \" + prefix)\n",
    "            X = datasets[dataset]['X_train' + data_variant]\n",
    "            y = datasets[dataset]['y_train']\n",
    "            grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=4, n_jobs=7, verbose = 1)\n",
    "            datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "            result['dataset'], result['data_variant'], result['scoring'] = str(dataset), data_variant, scoring\n",
    "            results = pd.concat([results, result])\n",
    "\n",
    "results.to_csv('logistic_regression_step_1.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej zestawienie parametrów dla 10 najlepszych uzyskanych wartości miar AUC i F1.\n",
    "Jakość uzyskiwanych modeli nie jest wysoka.\n",
    "\n",
    "Analiza przedstawionych danych pozwala stwierdzić, że:\n",
    "\n",
    "- różnice miar pomiędzy zbiorem testowym i treningowym są niewielkie (w granicach 1pp) --> model nie jest przeuczony,\n",
    "- jakość modelu nie zależy praktycznie od parametru C,\n",
    "- dla maksymalizacji AUC preferowane są zbiory z wagami WOE, dla maksymalizacji F-score - bez wag WOE,\n",
    "- dla obu miar preferowane są zbiory skalowane,\n",
    "- jakość modelu mocno zależy od parametru 'class_weight' - optymalna wartośc parametru to ok. 50 lub 'balanced'\n",
    "- w top 10 nie pojawiają się: \n",
    "    dataset 1 (= usunięte zmienne z brakami), \n",
    "    warianty danych z PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"logistic_regression_step_1.csv\", sep=';')\n",
    "results = results.drop(['params'], axis=1)\n",
    "\n",
    "results_best_auc = results[results['scoring']=='roc_auc']\n",
    "results_best_auc = results_best_auc.sort_values(by=['mean_test_score'], ascending=False)\n",
    "results_best_auc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_best_f1 = results[results['scoring']=='f1']\n",
    "results_best_f1 = results_best_f1.sort_values(by=['mean_test_score'], ascending=False)\n",
    "results_best_f1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'param_C', 'param_class_weight', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "classifier = LogisticRegression(C = 10**5, class_weight = 'balanced', random_state = 42, verbose = 0)\n",
    "weights = [10, 30, 40, 50, 60, 70, 80, 90]\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "param_grid = {'class_weight': class_weight}\n",
    "\n",
    "for dataset in [2, 3, 4]:\n",
    "    for data_variant in ['_scaled', '_woe_scaled']:\n",
    "        prefix = 'logistic_regression_2_' + str(dataset) + '_' + data_variant\n",
    "        print(\"start: \" + prefix)\n",
    "        X = datasets[dataset]['X_train' + data_variant]\n",
    "        y = datasets[dataset]['y_train']\n",
    "        grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring='roc_auc', cv=4, n_jobs=11, verbose = 0)\n",
    "        datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "        result['dataset'], result['data_variant'] = str(dataset), data_variant\n",
    "        results = pd.concat([results, result])\n",
    "\n",
    "results.to_csv('logistic_regression_step_2.csv', index=False, sep=';')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"logistic_regression_step_2.csv\", sep=';')\n",
    "results = results.drop(['params'], axis=1)\n",
    "results = results.sort_values(by=['mean_test_score'], ascending=False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki drugiego przebiegu Grid Search wskazują na:\n",
    "\n",
    "- sposób przygotowania danych '_woe_scaled' jako zwracający najlepsze wyniki,\n",
    "- przewagę drugiego datasetu (uzupełnienie braków medianą),\n",
    "- zakres optywamllnych wartości dla przeważenia klas w zmiennej obserwowanej: 40-80,\n",
    "- brak przeuczenia - średni wynik na zbiorach uczących i testowych jest prawie taki sam.\n",
    "\n",
    "Kolejnym krokiem będzie wygenerowanie zestawu modeli z wykorzystaniem całego zbioru uczącego dla:\n",
    "- wszystkich datasetów,\n",
    "- wszystkich sposobów przygotowania danych,\n",
    "- dla różnych wartości parametrów 'class_weight' w zakresie wskazanym przez Grid Search.\n",
    "\n",
    "Dla każdego modelu zwrócony zostanie zestaw miar zarówno dla zbioru uczącego jak i testowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - modelowanie\n",
    "dataset_columns = ['dataset', 'data_variant', 'class_weight', 'auc_train', 'auc_test', 'f1_train', 'f1_test', \n",
    "                   'accuracy_train', 'accuracy_test', 'precision_train', 'precision_test', 'recall_train', \n",
    "                   'recall_test', 'TN_train', 'TN_test', 'FN_train', 'FN_test', 'FP_train',  'FP_test', \n",
    "                   'TP_train', 'TP_test']\n",
    "\n",
    "model_results = pd.DataFrame(columns = dataset_columns)\n",
    "\n",
    "train_columns_rename = {'accuracy':'accuracy_train', 'precision':'precision_train', 'recall':'recall_train', \n",
    "                        'f1':'f1_train', 'auc':'auc_train', 'TP':'TP_train', 'FP':'FP_train', 'TN':'TN_train', \n",
    "                        'FN':'FN_train'}\n",
    "\n",
    "test_columns_rename = {'accuracy':'accuracy_test', 'precision':'precision_test', 'recall':'recall_test', \n",
    "                       'f1':'f1_test', 'auc':'auc_test', 'TP':'TP_test', 'FP':'FP_test', 'TN':'TN_test', \n",
    "                       'FN':'FN_test'}\n",
    "                             \n",
    "weights = range(40, 80, 5)\n",
    "class_weights = [{0:1, 1:x} for x in weights]\n",
    "class_weights.append('balanced')\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for class_weight in class_weights:\n",
    "            X_train = datasets[dataset]['X_train' + data_variant]\n",
    "            y_train = datasets[dataset]['y_train']\n",
    "            X_test = datasets[dataset]['X_test' + data_variant]\n",
    "            y_test = datasets[dataset]['y_test']               \n",
    "            model = LogisticRegression(C = 10**5, class_weight = class_weight, random_state = 42, n_jobs = -1)\n",
    "            model.fit(X_train, y_train)\n",
    "            train = pd.DataFrame.from_dict(get_measures(model, X_train, y_train), orient = 'index').transpose()\n",
    "            test  = pd.DataFrame.from_dict(get_measures(model, X_test , y_test ), orient = 'index').transpose()\n",
    "            train = train.rename(columns = train_columns_rename)\n",
    "            test  = test.rename(columns = test_columns_rename)\n",
    "            result = pd.concat([train, test], axis = 1)\n",
    "            result['dataset'] = dataset\n",
    "            result['data_variant'] = data_variant\n",
    "            result['class_weight'] = class_weight[1]\n",
    "            result = result[dataset_columns]\n",
    "            model_results = pd.concat([model_results, result])\n",
    "\n",
    "model_results.to_csv('logistic_regression_modelling.csv', index=False, sep=';')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"logistic_regression_modelling.csv\", sep=';')\n",
    "results = results.sort_values(by=['auc_train'], ascending=False)\n",
    "results = results[['dataset', 'data_variant', 'class_weight', 'auc_train', 'auc_test', 'f1_train', 'accuracy_train']]\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyżej przedstawiono 10 najlepszych modeli (sortowanie wg AUC na zbiorze treningowym malejąco).\n",
    "Jakość modeli nie jest zadowalająca - niski f-score, dość niska wartość AUC --> siła predykcyjna modelu jest niska."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drzewa decyzyjne\n",
    "\n",
    "Kolejna próba wykorzystuje jako klasyfikator drzewa decyzyjne.\n",
    "Dla klasyfikatorów drzewiastych liniowe przeskalowanie danych jest transparentne i nie wpływa na wynik, dlatego nie badam wszystkich wariantów przygotowania danych jak w przypadku regresji logistycznej.\n",
    "\n",
    "Procedura optymalizacji modelu jest analogiczna jak w przypadku regresji logistycznej:\n",
    "- Grid Search + Cross Validation z przeszukaniem szerokiego zakresu parametrów klasyfikatora,\n",
    "- modelowanie dla najlepiej rokujących zestawów parametrów.\n",
    "\n",
    "Do optymalizacji uwzględniam:\n",
    "- maksymalną długość drzewa,\n",
    "- liczbę zmiennych branych pod uwagę w wyborze najlepszego podziału (parametr ten wprowadza element losowości),\n",
    "- wagi dla klas zmiennej objaśnianej (z uwagi na nierównomierną liczność klas).\n",
    "\n",
    "Uwzględniając doświadczenia z modelowania metodą regresji logistycznej pomijam pierwszy dataset w dalszych analizach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=None, max_features=None, random_state=42, class_weight=None)\n",
    "\n",
    "max_depth = [3, 5, 7, 9, 11, 15, 20]\n",
    "max_features = [None, 0.5, 0.75]\n",
    "weights = [30, 40, 50, 60, 70, 80, 90]\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "class_weight.append(None)\n",
    "param_grid = {'max_depth': max_depth, 'max_features': max_features, 'class_weight':class_weight}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "for dataset in [2, 3, 4]:\n",
    "    for data_variant in ['_pca', '_scaled', '_woe_scaled', '_woe_pca']:\n",
    "        prefix = 'decision_tree_' + str(dataset) + '_' + data_variant\n",
    "        print(\"start: \" + prefix)\n",
    "        X = datasets[dataset]['X_train' + data_variant]\n",
    "        y = datasets[dataset]['y_train']\n",
    "        grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring='roc_auc', cv=4, n_jobs=-1, verbose = 0)\n",
    "        datasets[dataset]['grid_search_decision_tree_' + data_variant + '_' + scoring] = grid_search\n",
    "        result['dataset'], result['data_variant'] = str(dataset), data_variant\n",
    "        results = pd.concat([results, result])\n",
    "\n",
    "results.to_csv('decision_tree_grid_search.csv', index=False, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"decision_tree_grid_search.csv\", sep=';')\n",
    "results = results.sort_values(by=['mean_test_score'], ascending=False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizując uzyskane wyniki można stwierdzić, że:\n",
    "\n",
    "- wśród najwyżej ocenianych nie występują zbiory przygotowane z wykorzystaniem PCA,\n",
    "- różnica pomiędzy średnim wynikiem dla zbiorów testowych i treningowych nie przekracza 3pp --> modele nie są przeuczone,\n",
    "- optymalna wartośc parametru 'class_weight' znajduje się w granicach 60-90\n",
    "- optymalna wartość parametru 'max_depth' znajduje się w granicach 5-7\n",
    "- optymalna wartość parametru 'max_features' znajduje się w granicach 75-100%\n",
    "\n",
    "Kolejnym krokiem jest modelowanie w zakresach parametrów wskazanych przez Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drzewa decyzyjne - modelowanie\n",
    "dataset_columns = ['dataset', 'data_variant', 'class_weight', 'auc_train', 'auc_test', 'f1_train', 'f1_test', \n",
    "                   'accuracy_train', 'accuracy_test', 'precision_train', 'precision_test', 'recall_train', \n",
    "                   'recall_test', 'TN_train', 'TN_test', 'FN_train', 'FN_test', 'FP_train',  'FP_test', \n",
    "                   'TP_train', 'TP_test']\n",
    "\n",
    "model_results = pd.DataFrame(columns = dataset_columns)\n",
    "\n",
    "train_columns_rename = {'accuracy':'accuracy_train', 'precision':'precision_train', 'recall':'recall_train', \n",
    "                        'f1':'f1_train', 'auc':'auc_train', 'TP':'TP_train', 'FP':'FP_train', 'TN':'TN_train', \n",
    "                        'FN':'FN_train'}\n",
    "\n",
    "test_columns_rename = {'accuracy':'accuracy_test', 'precision':'precision_test', 'recall':'recall_test', \n",
    "                       'f1':'f1_test', 'auc':'auc_test', 'TP':'TP_test', 'FP':'FP_test', 'TN':'TN_test', \n",
    "                       'FN':'FN_test'}\n",
    "                             \n",
    "weights = range(50, 90, 10)\n",
    "class_weights = [{0:1, 1:x} for x in weights]\n",
    "max_depths = [5, 6, 7]\n",
    "max_features_set = [0.75, None]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for max_depth in max_depths:\n",
    "            for max_features in max_features_set:\n",
    "                for class_weight in class_weights:\n",
    "                    X_train = datasets[dataset]['X_train' + data_variant]\n",
    "                    y_train = datasets[dataset]['y_train']\n",
    "                    X_test = datasets[dataset]['X_test' + data_variant]\n",
    "                    y_test = datasets[dataset]['y_test']               \n",
    "                    model = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features, random_state=42, class_weight=class_weight)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    train = pd.DataFrame.from_dict(get_measures(model, X_train, y_train), orient = 'index').transpose()\n",
    "                    test  = pd.DataFrame.from_dict(get_measures(model, X_test , y_test ), orient = 'index').transpose()\n",
    "                    train = train.rename(columns = train_columns_rename)\n",
    "                    test  = test.rename(columns = test_columns_rename)\n",
    "                    result = pd.concat([train, test], axis = 1)\n",
    "                    result['dataset'] = dataset\n",
    "                    result['data_variant'] = data_variant\n",
    "                    result['class_weight'] = class_weight[1]\n",
    "                    result = result[dataset_columns]\n",
    "                    model_results = pd.concat([model_results, result])\n",
    "\n",
    "model_results.to_csv('decision_tree_modelling.csv', index=False, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"decision_tree_modelling.csv\", sep=';')\n",
    "results = results[results['auc_train'] - results['auc_test'] < 0.05]\n",
    "results = results.sort_values(by=['auc_train'], ascending=False)\n",
    "results = results[['dataset', 'data_variant', 'class_weight', 'auc_train', 'auc_test', 'f1_train', 'accuracy_train']]\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla modeli z najwyższą wartością AUC występuje znaczna różnica pomiędzy AUC dla zbioru testowego i treningowego, co wskazuje na przeuczenie modelu. Dlatego ograniczyłem analizowane wyniki wyłącznie do modeli, dla których różnica w ocenach zbioru testowego i treningowego nie przekracza 5pp AUC.\n",
    "\n",
    "Najlepszy model wykazuje 81% AUC przy bardzo słabej wartości f-score. Siła predykcyjna tego modelu jest słaba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Następnym klasyfikatorem użytym w modelowaniu są lasy losowe.\n",
    "Jest to naturalne rozszerzenie klasyfikacji za pomocą drzew.\n",
    "\n",
    "W optymalizacji korzystam z wypracowanego schematu postępowania, optymalizacji podlegają te same parametry, co w przypadku drzew decyzyjnych, dodatkowo optymalizuję parametr liczby estymatorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 100, max_depth=None, max_features=None, random_state=42, class_weight=None)\n",
    "\n",
    "n_estimators = [100, 300, 400, 500, 700]\n",
    "max_depth = [5, 6, 7, 8, 9]\n",
    "max_features = [None, 0.75, 0.90]\n",
    "weights = [40, 60, 80]\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "class_weight.append(None)\n",
    "param_grid = {'n_estimators':n_estimators, 'max_depth': max_depth, 'max_features': max_features, 'class_weight':class_weight}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "for dataset in [2, 3, 4]:\n",
    "    for data_variant in ['_scaled', '_woe_scaled']:\n",
    "        prefix = 'random_forest_' + str(dataset) + '_' + data_variant\n",
    "        print(\"start: \" + prefix)\n",
    "        X = datasets[dataset]['X_train' + data_variant]\n",
    "        y = datasets[dataset]['y_train']\n",
    "        grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring='roc_auc', cv=3, n_jobs=-1, verbose = 1)\n",
    "        datasets[dataset]['grid_search_random_forest_' + data_variant] = grid_search\n",
    "        result['dataset'], result['data_variant'] = str(dataset), data_variant\n",
    "        results = pd.concat([results, result])\n",
    "\n",
    "results.to_csv('random_forest_grid_search.csv', index=False, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"random_forest_grid_search.csv\", sep=';')\n",
    "# results = results[results['mean_train_score'] - results['mean_test_score'] < 0.05]\n",
    "results = results.sort_values(by=['mean_test_score'], ascending=False)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"random_forest_grid_search.csv\", sep=';')\n",
    "results = results[results['mean_train_score'] - results['mean_test_score'] < 0.05]\n",
    "results = results.sort_values(by=['mean_test_score'], ascending=False)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki miar jakości modeli uzyskanych w Grid Search w zależności od parametrów klasyfikatora posortowałem malejąco wg średniej wartości AUC dla zbioru testowego. Analizując wyniki zwrócone dla najlepszych 20 szacowań (powyżej) można stwierdzić, że: \n",
    "- róznica na AUC pomiędzy zbiorem testowym i treningowym przekracza 5pp, co może wskazywać na przeuczenie modeli,\n",
    "- występuje wyłącznie dataset 2,\n",
    "- jako waga dla klasy objaśnianej występuje prawie wyłącznie wartość 40, \n",
    "- parametr max_depth występuje w granicach 6-7,\n",
    "- parametr max_features występuje wyłącznie w wartości 0.75\n",
    "- dominuje 'class_weight' na poziomie 40\n",
    "- przeważa ;max_weight' na poziomie 75%,\n",
    "- jakość modelu jest nieczuła na liczbę klasyfikatorów w badanym zakresie\n",
    "\n",
    "Po wprowadzeniu ograniczenia w zbiorze wyników - dopuszczalna różnica AUC_train - AUC_test < 5% (wykluczenie modeli przeuczonych; wyniki poniżej):\n",
    "- wcześniejsze obserwacje pozostają w mocy.\n",
    "\n",
    "Dziwi brak czułości metody na parametr liczby estymatorów - prawdopodobnie przeszukiwany zestaw zawierał zbyt wysokie wartości. Podobnie wskazana wartość 'class_weight' to najniższa wartość w badanym zestawie. Niestety ze wzgledu na długi czas obliczeń nie byłem w stanie przetworzyć ponownie Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest - modelowanie\n",
    "dataset_columns = ['dataset', 'data_variant', 'n_estimators', 'max_depth', 'max_features', 'class_weight', \n",
    "                   'auc_train', 'auc_test', 'f1_train', 'f1_test', 'accuracy_train', 'accuracy_test', \n",
    "                   'precision_train', 'precision_test', 'recall_train', 'recall_test', 'TN_train', \n",
    "                   'TN_test', 'FN_train', 'FN_test', 'FP_train',  'FP_test', 'TP_train', 'TP_test']\n",
    "\n",
    "model_results = pd.DataFrame(columns = dataset_columns)\n",
    "\n",
    "train_columns_rename = {'accuracy':'accuracy_train', 'precision':'precision_train', 'recall':'recall_train', \n",
    "                        'f1':'f1_train', 'auc':'auc_train', 'TP':'TP_train', 'FP':'FP_train', 'TN':'TN_train', \n",
    "                        'FN':'FN_train'}\n",
    "\n",
    "test_columns_rename = {'accuracy':'accuracy_test', 'precision':'precision_test', 'recall':'recall_test', \n",
    "                       'f1':'f1_test', 'auc':'auc_test', 'TP':'TP_test', 'FP':'FP_test', 'TN':'TN_test', \n",
    "                       'FN':'FN_test'}\n",
    "\n",
    "n_estimators_set = [10, 50, 100, 300] \n",
    "weights = range(20, 60, 5)\n",
    "class_weights = [{0:1, 1:x} for x in weights]\n",
    "max_depths = [5, 6, 7, 8]\n",
    "max_features_set = [0.65, 0.75, 0.85]\n",
    "\n",
    "for dataset in [2, 3, 4]:\n",
    "    for data_variant in ['_scaled', '_woe_scaled']:\n",
    "        for n_estimators in n_estimators_set:\n",
    "            for max_depth in max_depths:\n",
    "                for max_features in max_features_set:\n",
    "                    for class_weight in class_weights:\n",
    "                        X_train = datasets[dataset]['X_train' + data_variant]\n",
    "                        y_train = datasets[dataset]['y_train']\n",
    "                        X_test = datasets[dataset]['X_test' + data_variant]\n",
    "                        y_test = datasets[dataset]['y_test']               \n",
    "                        model = RandomForestClassifier(n_estimators = n_estimators, max_depth=max_depth, max_features=max_features, random_state=42, class_weight=class_weight, n_jobs=3)\n",
    "                        model.fit(X_train, y_train)\n",
    "                        train = pd.DataFrame.from_dict(get_measures(model, X_train, y_train), orient = 'index').transpose()\n",
    "                        test  = pd.DataFrame.from_dict(get_measures(model, X_test , y_test ), orient = 'index').transpose()\n",
    "                        train = train.rename(columns = train_columns_rename)\n",
    "                        test  = test.rename(columns = test_columns_rename)\n",
    "                        result = pd.concat([train, test], axis = 1)\n",
    "                        result['dataset'] = dataset\n",
    "                        result['data_variant'] = data_variant\n",
    "                        result['n_estimators'] = n_estimators\n",
    "                        result['max_depth'] = max_depth\n",
    "                        result['max_features'] = max_features\n",
    "                        result['class_weight'] = class_weight[1]\n",
    "                        result = result[dataset_columns]\n",
    "                        model_results = pd.concat([model_results, result])\n",
    "\n",
    "model_results.to_csv('random_forest_modelling.csv', index=False, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.01, 0.05, 0.1],\n",
       " 'n_estimators': [20, 50, 100, 200, 500],\n",
       " 'max_depth': [3, 5, 7],\n",
       " 'max_features': [None, 0.5, 0.75, 0.9]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, subsample=1., max_depth=5, max_features=None, \n",
    "                                        random_state=42, verbose=1)\n",
    "    \n",
    "learning_rate = [0.01, 0.05, 0.1]\n",
    "n_estimators = [20, 50, 100, 200, 500]\n",
    "max_depth = [3, 5, 7]\n",
    "max_features = [None, 0.5, 0.75, 0.9]                            \n",
    "param_grid = {'learning_rate': learning_rate, 'n_estimators': n_estimators, 'max_depth':max_depth, 'max_features':max_features}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: gradient_boosting_2__pca\n",
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed: 92.0min\n",
      "[Parallel(n_jobs=3)]: Done 720 out of 720 | elapsed: 157.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1511            1.74m\n",
      "         2           0.1498            1.66m\n",
      "         3           0.1487            1.62m\n",
      "         4           0.1476            1.62m\n",
      "         5           0.1465            1.61m\n",
      "         6           0.1458            1.58m\n",
      "         7           0.1448            1.57m\n",
      "         8           0.1440            1.57m\n",
      "         9           0.1431            1.56m\n",
      "        10           0.1423            1.56m\n",
      "        20           0.1348            1.53m\n",
      "        30           0.1296            1.50m\n",
      "        40           0.1252            1.46m\n",
      "        50           0.1216            1.42m\n",
      "        60           0.1184            1.39m\n",
      "        70           0.1157            1.35m\n",
      "        80           0.1133            1.32m\n",
      "        90           0.1113            1.28m\n",
      "       100           0.1095            1.24m\n",
      "       200           0.0966           54.80s\n",
      "       300           0.0894           35.99s\n",
      "       400           0.0856           17.68s\n",
      "       500           0.0822            0.00s\n",
      "start: gradient_boosting_2__scaled\n",
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed: 71.1min\n",
      "[Parallel(n_jobs=3)]: Done 720 out of 720 | elapsed: 121.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1505           14.94s\n",
      "         2           0.1484           14.91s\n",
      "         3           0.1469           14.87s\n",
      "         4           0.1454           14.84s\n",
      "         5           0.1440           15.11s\n",
      "         6           0.1429           15.77s\n",
      "         7           0.1420           15.94s\n",
      "         8           0.1408           15.89s\n",
      "         9           0.1399           15.78s\n",
      "        10           0.1392           15.49s\n",
      "        20           0.1336           15.15s\n",
      "        30           0.1303           14.78s\n",
      "        40           0.1283           14.39s\n",
      "        50           0.1268           13.85s\n",
      "        60           0.1256           13.46s\n",
      "        70           0.1246           13.01s\n",
      "        80           0.1237           12.58s\n",
      "        90           0.1231           12.18s\n",
      "       100           0.1225           11.74s\n",
      "       200           0.1177            8.28s\n",
      "       300           0.1139            5.40s\n",
      "       400           0.1111            2.65s\n",
      "       500           0.1086            0.00s\n",
      "start: gradient_boosting_2__woe_scaled\n",
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Ja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed: 94.4min\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "for dataset in [2, 3, 4]:\n",
    "    for data_variant in ['_pca', '_scaled', '_woe_scaled', '_woe_pca']:\n",
    "        prefix = 'gradient_boosting_' + str(dataset) + '_' + data_variant\n",
    "        print(\"start: \" + prefix)\n",
    "        X = datasets[dataset]['X_train' + data_variant]\n",
    "        y = datasets[dataset]['y_train']\n",
    "        grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring='roc_auc', cv=4, n_jobs=3, verbose = 1)\n",
    "        datasets[dataset]['grid_search_gradient_boosting_' + data_variant] = grid_search\n",
    "        result['dataset'], result['data_variant'] = str(dataset), data_variant\n",
    "        results = pd.concat([results, result])\n",
    "\n",
    "results.to_csv('gradient_boosting_grid_search.csv', index=False, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - druga przymiarka\n",
    "\n",
    "# klasyfikator + parametry do grid_searcha\n",
    "classifier = LogisticRegression(C = 10**5, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "weights = [30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160]\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "param_grid = {'class_weight': class_weight}\n",
    "\n",
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'scoring', 'param_class_weight', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for scoring in ['roc_auc', 'f1']:\n",
    "            prefix = 'logistic_regression_2_' + str(dataset) + '_' + data_variant + '_' + scoring\n",
    "            print(\"start: \" + prefix)\n",
    "            X = datasets[dataset]['X_train' + data_variant]\n",
    "            y = datasets[dataset]['y_train']\n",
    "            grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=4, n_jobs=7, verbose = 1)\n",
    "            datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "            result['dataset'], result['data_variant'], result['scoring'] = str(dataset), data_variant, scoring\n",
    "            results = pd.concat([results, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - trzecia przymiarka\n",
    "\n",
    "# klasyfikator + parametry do grid_searcha\n",
    "classifier = LogisticRegression(C = 10**5, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "weights = range(20, 100, 5)\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "param_grid = {'class_weight': class_weight}\n",
    "\n",
    "data_variants = ['', '_scaled', '_woe_scaled']\n",
    "\n",
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'scoring', 'param_class_weight', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for scoring in ['roc_auc', 'f1']:\n",
    "            prefix = 'logistic_regression_3_' + str(dataset) + '_' + data_variant + '_' + scoring\n",
    "            print(\"start: \" + prefix)\n",
    "            X = datasets[dataset]['X_train' + data_variant]\n",
    "            y = datasets[dataset]['y_train']\n",
    "            grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=4, n_jobs=7, verbose = 1)\n",
    "            datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "            result['dataset'], result['data_variant'], result['scoring'] = str(dataset), data_variant, scoring\n",
    "            results = pd.concat([results, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - czwarta przymiarka\n",
    "\n",
    "# klasyfikator + parametry do grid_searcha\n",
    "classifier = LogisticRegression(C = 10**5, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "weights = range(0, 20, 5)\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "param_grid = {'class_weight': class_weight}\n",
    "\n",
    "data_variants = ['', '_scaled', '_woe_scaled']\n",
    "\n",
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'scoring', 'param_class_weight', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for scoring in ['roc_auc', 'f1']:\n",
    "            prefix = 'logistic_regression_4_' + str(dataset) + '_' + data_variant + '_' + scoring\n",
    "            print(\"start: \" + prefix)\n",
    "            X = datasets[dataset]['X_train' + data_variant]\n",
    "            y = datasets[dataset]['y_train']\n",
    "            grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=4, n_jobs=7, verbose = 1)\n",
    "            datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "            result['dataset'], result['data_variant'], result['scoring'] = str(dataset), data_variant, scoring\n",
    "            results = pd.concat([results, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - piąta przymiarka\n",
    "\n",
    "# klasyfikator + parametry do grid_searcha\n",
    "classifier = LogisticRegression(C = 10**5, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "weights = range(10, 30, 1)\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "param_grid = {'class_weight': class_weight}\n",
    "\n",
    "data_variants = ['', '_scaled', '_woe_scaled']\n",
    "\n",
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'scoring', 'param_class_weight', 'params', 'mean_train_score', 'mean_test_score'])\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for scoring in ['roc_auc', 'f1']:\n",
    "            prefix = 'logistic_regression_5_' + str(dataset) + '_' + data_variant + '_' + scoring\n",
    "            print(\"start: \" + prefix)\n",
    "            X = datasets[dataset]['X_train' + data_variant]\n",
    "            y = datasets[dataset]['y_train']\n",
    "            grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=4, n_jobs=7, verbose = 1)\n",
    "            datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "            result['dataset'], result['data_variant'], result['scoring'] = str(dataset), data_variant, scoring\n",
    "            results = pd.concat([results, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = LogisticRegression(C = 10**5, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "# m.fit(datasets[1]['X_train'], datasets[1]['y_train'])\n",
    "# d = get_measures(m, datasets[1]['X_train'], datasets[1]['y_train'])\n",
    "d1 = pd.DataFrame.from_dict(d, orient = 'index').transpose()\n",
    "d2 = pd.DataFrame.from_dict(d, orient = 'index').transpose()\n",
    "d1 = d1.rename(columns = {'accuracy':'accuracy_train', 'precision':'precision_train', 'recall':'recall_train', 'f1':'f1_train', 'auc':'auc_train', 'TP':'TP_train', 'FP':'FP_train', 'TN':'TN_train', 'FN':'FN_train'})\n",
    "d2 = d2.rename(columns = {'accuracy':'accuracy_test', 'precision':'precision_test', 'recall':'recall_test', 'f1':'f1_test', 'auc':'auc_test', 'TP':'TP_test', 'FP':'FP_test', 'TN':'TN_test', 'FN':'FN_test'})\n",
    "df = pd.concat([d1, d2], axis = 1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - modelowanie\n",
    "dataset_columns = ['dataset', 'data_variant', 'class_weight', 'auc_train', 'auc_test', 'f1_train', 'f1_test', \n",
    "                   'accuracy_train', 'accuracy_test', 'precision_train', 'precision_test', 'recall_train', 'recall_test',\n",
    "                   'TN_train', 'TN_test', 'FN_train', 'FN_test', 'FP_train',  'FP_test', 'TP_train', 'TP_test']\n",
    "\n",
    "model_results = pd.DataFrame(columns = dataset_columns)\n",
    "\n",
    "train_columns_rename = {'accuracy':'accuracy_train', 'precision':'precision_train', 'recall':'recall_train', 'f1':'f1_train',\n",
    "                        'auc':'auc_train', 'TP':'TP_train', 'FP':'FP_train', 'TN':'TN_train', 'FN':'FN_train'}\n",
    "test_columns_rename = {'accuracy':'accuracy_test', 'precision':'precision_test', 'recall':'recall_test', 'f1':'f1_test', 'auc':'auc_test', 'TP':'TP_test', 'FP':'FP_test', 'TN':'TN_test', 'FN':'FN_test'}\n",
    "                             \n",
    "weights = range(1, 80, 4)\n",
    "class_weights = [{0:1, 1:x} for x in weights]\n",
    "class_weights.append('balanced')\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for class_weight in class_weights:\n",
    "            X_train = datasets[dataset]['X_train' + data_variant]\n",
    "            y_train = datasets[dataset]['y_train']\n",
    "            X_test = datasets[dataset]['X_test' + data_variant]\n",
    "            y_test = datasets[dataset]['y_test']               \n",
    "            model = LogisticRegression(C = 10**5, class_weight = class_weight, random_state = 42, verbose = 1)\n",
    "            model.fit(X_train, y_train)\n",
    "            train = pd.DataFrame.from_dict(get_measures(model, X_train, y_train), orient = 'index').transpose()\n",
    "            test  = pd.DataFrame.from_dict(get_measures(model, X_test , y_test ), orient = 'index').transpose()\n",
    "            train = train.rename(columns = train_columns_rename)\n",
    "            test  = test.rename(columns = test_columns_rename)\n",
    "            result = pd.concat([train, test], axis = 1)\n",
    "            result['dataset'] = dataset\n",
    "            result['data_variant'] = data_variant\n",
    "            result['class_weight'] = class_weight[1]\n",
    "            result = result[dataset_columns]\n",
    "            model_results = pd.concat([model_results, result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['dataset', 'data_variant', 'class_weight', 'auc_train', 'auc_test', 'f1_train', 'f1_test', \n",
    " 'accuracy_train', 'accuracy_test', 'precision_train', 'precision_test', 'recall_train', 'recall_test',\n",
    " 'TN_train', 'TN_test', 'FN_train', 'FN_test', 'FP_train',  'FP_test', 'TP_train', 'TP_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna - modelowanie\n",
    "dataset_columns = ['dataset', 'data_variant', 'class_weight', 'auc_train', 'auc_test', 'f1_train', 'f1_test', \n",
    "                   'accuracy_train', 'accuracy_test', 'precision_train', 'precision_test', 'recall_train', 'recall_test',\n",
    "                   'TN_train', 'TN_test', 'FN_train', 'FN_test', 'FP_train',  'FP_test', 'TP_train', 'TP_test']\n",
    "\n",
    "model_results = pd.DataFrame(columns = dataset_columns)\n",
    "\n",
    "train_columns_rename = {'accuracy':'accuracy_train', 'precision':'precision_train', 'recall':'recall_train', 'f1':'f1_train',\n",
    "                        'auc':'auc_train', 'TP':'TP_train', 'FP':'FP_train', 'TN':'TN_train', 'FN':'FN_train'}\n",
    "test_columns_rename = {'accuracy':'accuracy_test', 'precision':'precision_test', 'recall':'recall_test', 'f1':'f1_test', 'auc':'auc_test', 'TP':'TP_test', 'FP':'FP_test', 'TN':'TN_test', 'FN':'FN_test'}\n",
    "                             \n",
    "weights = range(1, 80, 4)\n",
    "class_weights = [{0:1, 1:x} for x in weights]\n",
    "class_weights.append('balanced')\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for class_weight in class_weights:\n",
    "            X_train = datasets[dataset]['X_train' + data_variant]\n",
    "            y_train = datasets[dataset]['y_train']\n",
    "            X_test = datasets[dataset]['X_test' + data_variant]\n",
    "            y_test = datasets[dataset]['y_test']               \n",
    "            model = LogisticRegression(C = 10**5, class_weight = class_weight, random_state = 42, verbose = 1)\n",
    "            model.fit(X_train, y_train)\n",
    "            train = pd.DataFrame.from_dict(get_measures(model, X_train, y_train), orient = 'index').transpose()\n",
    "            test  = pd.DataFrame.from_dict(get_measures(model, X_test , y_test ), orient = 'index').transpose()\n",
    "            train = train.rename(columns = train_columns_rename)\n",
    "            test  = test.rename(columns = test_columns_rename)\n",
    "            result = pd.concat([train, test], axis = 1)\n",
    "            result['dataset'] = dataset\n",
    "            result['data_variant'] = data_variant\n",
    "            result['class_weight'] = class_weight[1]\n",
    "            result = result[dataset_columns]\n",
    "            model_results = pd.concat([model_results, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.to_csv('logistic_regression_modelling.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost - pierwsza przymiarka\n",
    "\n",
    "# klasyfikator + parametry do grid_searcha\n",
    "classifier = xgboost.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, verbosity=1, scale_pos_weight=1)\n",
    "\n",
    "max_depth = [3, 5, 7, 9, 11]\n",
    "learning_rate = [0.001, 0.01, 0.1, 1.]\n",
    "n_estimators = [50, 200, 500, 700]\n",
    "scale_pos_weight = [1, 10, 30, 50]\n",
    "\n",
    "param_grid = {'max_depth': max_depth, 'learning_rate':learning_rate, 'n_estimators':n_estimators, 'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'scoring', 'param_max_depth', 'param_learning_rate', \n",
    "                                  'param_n_estimators', 'param_scale_pos_weight',  'params', 'mean_train_score', \n",
    "                                  'mean_test_score'])\n",
    "\n",
    "data_variants = ['_scaled', '_woe_scaled']\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for scoring in ['roc_auc', 'f1']:\n",
    "            prefix = 'xgb_1_' + str(dataset) + '_' + data_variant + '_' + scoring\n",
    "            print(\"start: \" + prefix)\n",
    "            X = datasets[dataset]['X_train' + data_variant]\n",
    "            y = datasets[dataset]['y_train']\n",
    "            grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=4, n_jobs=11, verbose = 1)\n",
    "            datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "            result['dataset'], result['data_variant'], result['scoring'] = str(dataset), data_variant, scoring\n",
    "            results = pd.concat([results, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost - druga przymiarka\n",
    "\n",
    "# klasyfikator + parametry do grid_searcha\n",
    "classifier = xgboost.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, verbosity=1, scale_pos_weight=1)\n",
    "\n",
    "max_depth = [3, 5, 7]\n",
    "learning_rate = [0.01, 0.1]\n",
    "n_estimators = [200, 400, 600]\n",
    "scale_pos_weight = [20, 40, 60]\n",
    "\n",
    "param_grid = {'max_depth': max_depth, 'learning_rate':learning_rate, 'n_estimators':n_estimators, 'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns = ['dataset', 'data_variant', 'scoring', 'param_max_depth', 'param_learning_rate', \n",
    "                                  'param_n_estimators', 'param_scale_pos_weight',  'params', 'mean_train_score', \n",
    "                                  'mean_test_score'])\n",
    "\n",
    "\n",
    "data_variants = ['_scaled', '_woe_scaled']\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for scoring in ['roc_auc', 'f1']:\n",
    "            prefix = 'xgb_2_' + str(dataset) + '_' + data_variant + '_' + scoring\n",
    "            print(\"start: \" + prefix)\n",
    "            X = datasets[dataset]['X_train' + data_variant]\n",
    "            y = datasets[dataset]['y_train']\n",
    "            grid_search, result = model_grid_search(prefix, classifier, param_grid, X, y, scoring, cv=3, n_jobs=11, verbose = 1)\n",
    "            datasets[dataset]['grid_search_logistic_regression_' + data_variant + '_' + scoring] = grid_search\n",
    "            result['dataset'], result['data_variant'], result['scoring'] = str(dataset), data_variant, scoring\n",
    "            results = pd.concat([results, result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('gb_2.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XGBoost - modelowanie\n",
    "dataset_columns = ['dataset', 'data_variant', 'param_max_depth', 'param_n_estimators', 'param_scale_pos_weight',\n",
    "                   'auc_train', \n",
    "                   'auc_test', 'f1_train', 'f1_test', 'accuracy_train', 'accuracy_test', 'precision_train', \n",
    "                   'precision_test', 'recall_train', 'recall_test', 'TN_train', 'TN_test', 'FN_train', \n",
    "                   'FN_test', 'FP_train',  'FP_test', 'TP_train', 'TP_test']\n",
    "\n",
    "model_results = pd.DataFrame(columns = dataset_columns)\n",
    "\n",
    "train_columns_rename = {'accuracy':'accuracy_train', 'precision':'precision_train', 'recall':'recall_train', 'f1':'f1_train',\n",
    "                        'auc':'auc_train', 'TP':'TP_train', 'FP':'FP_train', 'TN':'TN_train', 'FN':'FN_train'}\n",
    "\n",
    "test_columns_rename = {'accuracy':'accuracy_test', 'precision':'precision_test', 'recall':'recall_test', 'f1':'f1_test', 'auc':'auc_test', 'TP':'TP_test', 'FP':'FP_test', 'TN':'TN_test', 'FN':'FN_test'}\n",
    "                             \n",
    "max_depths = [3, 4, 5, 6]\n",
    "n_estimators_set = [400, 500, 600]\n",
    "scale_pos_weights = [30, 50, 70]\n",
    "\n",
    "data_variants = ['_pca', '_scaled', '_woe_scaled', '_woe_pca']\n",
    "\n",
    "for dataset in datasets:\n",
    "    for data_variant in data_variants:\n",
    "        for max_depth in max_depths:\n",
    "            for n_estimators in n_estimators_set:\n",
    "                for scale_pos_weight in scale_pos_weights:\n",
    "                    X_train = datasets[dataset]['X_train' + data_variant]\n",
    "                    y_train = datasets[dataset]['y_train']\n",
    "                    X_test = datasets[dataset]['X_test' + data_variant]\n",
    "                    y_test = datasets[dataset]['y_test']               \n",
    "                    model = xgboost.XGBClassifier(n_jobs=7, max_depth=max_depth, learning_rate=0.01, n_estimators=n_estimators, verbosity=1, scale_pos_weight=50)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    train = pd.DataFrame.from_dict(get_measures(model, X_train, y_train), orient = 'index').transpose()\n",
    "                    test  = pd.DataFrame.from_dict(get_measures(model, X_test , y_test ), orient = 'index').transpose()\n",
    "                    train = train.rename(columns = train_columns_rename)\n",
    "                    test  = test.rename(columns = test_columns_rename)\n",
    "                    result = pd.concat([train, test], axis = 1)\n",
    "                    result['dataset'] = dataset\n",
    "                    result['data_variant'] = data_variant\n",
    "                    result['param_max_depth'] = max_depth\n",
    "                    result['param_n_estimators'] = n_estimators\n",
    "                    result['param_scale_pos_weight'] = scale_pos_weight\n",
    "                    result = result[dataset_columns]\n",
    "                    model_results = pd.concat([model_results, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.to_csv('xgb_2_modelling.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [10**c for c in range(3, 9, 2)]\n",
    "weights = [1, 20, 50, 100, 200]\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "\n",
    "max_depth = [4, 5, 7,  9]\n",
    "n_estimators = [10, 100, 200, 400]\n",
    "max_features = ['sqrt', None]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.]\n",
    "\n",
    "classifiers = {\n",
    "    'log_reg' : \n",
    "    {\n",
    "        'param_grid':{'C': C, 'class_weight': class_weight}, \n",
    "        'classifier':LogisticRegression(C = 1.0, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "    },\n",
    "    'tree' : \n",
    "    {\n",
    "        'param_grid':{'max_depth':max_depth, 'class_weight':class_weight}, \n",
    "        'classifier':DecisionTreeClassifier(random_state=42, splitter='best', max_depth=10, class_weight='balanced')\n",
    "    },\n",
    "    'random_forest' : \n",
    "    {\n",
    "        'param_grid':{'max_depth':max_depth, 'class_weight':class_weight, 'n_estimators':n_estimators},\n",
    "        'classifier':RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42, class_weight='balanced', verbose=1)\n",
    "    },\n",
    "    'gradient_boosting' :\n",
    "    {\n",
    "        'param_grid':{'learning_rate':learning_rate, 'n_estimators':n_estimators, 'max_features':max_features},\n",
    "        'classifier':GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 10, random_state=42, max_features=None, verbose=1)\n",
    "    },\n",
    "    'xgboost' :\n",
    "    {\n",
    "        'param_grid':{'learning_rate':learning_rate, 'n_estimators':n_estimators, 'max_features':max_features},\n",
    "        'classifier':xgboost.XGBClassifier(learning_rate = 0.01, n_estimators = 10, random_state=42, max_features=None, verbose=1)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_variants = {\n",
    "    '1':{'X_train':set_1[0], 'y_train':set_1[2], 'X_test':set_1[1], 'y_test':set_1[3]},\n",
    "    '2':{'X_train':set_2[0], 'y_train':set_2[2], 'X_test':set_2[1], 'y_test':set_2[3]},\n",
    "    '3':{'X_train':set_3[0], 'y_train':set_3[2], 'X_test':set_3[1], 'y_test':set_3[3]},\n",
    "    '4':{'X_train':set_4[0], 'y_train':set_4[2], 'X_test':set_4[1], 'y_test':set_4[3]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_variants:\n",
    "    for model in classifiers:\n",
    "        model_grid_search(\n",
    "            data + '_' + model, \n",
    "            classifiers[model]['classifier'], \n",
    "            classifiers[model]['param_grid'], \n",
    "            data_variants[data]['X_train'], \n",
    "            data_variants[data]['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['log_reg']['classifier'] = LogisticRegression(C = 1000.0, class_weight = {0: 1, 1: 200}, random_state = 42, verbose = 0)\n",
    "classifiers['tree']['classifier'] = DecisionTreeClassifier(random_state=42, splitter='best', max_depth=6, class_weight={0: 1, 1: 1})\n",
    "classifiers['random_forest']['classifier'] = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42, class_weight={0: 1, 1: 50})\n",
    "classifiers['gradient_boosting']['classifier'] = GradientBoostingClassifier(learning_rate = 0.05, n_estimators = 150, random_state=42, max_features=None, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classifiers:\n",
    "    classifiers[item]['classifier'].fit(X_train_scaled, y_train)\n",
    "    train_assessment = get_measures(classifiers[item]['classifier'], X_train_scaled, y_train)\n",
    "    test_assessment = get_measures(classifiers[item]['classifier'], X_test_scaled, y_test)\n",
    "    print(f\"{item} AUC_train = {'{:1.3f}'.format(train_assessment[-2])} AUC_test = {'{:1.3f}'.format(train_assessment[-2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['log_reg']['classifier'] = LogisticRegression(C = 1000.0, class_weight = {0: 1, 1: 200}, random_state = 42, verbose = 0)\n",
    "classifiers['tree']['classifier'] = DecisionTreeClassifier(random_state=42, splitter='best', max_depth=6, class_weight={0: 1, 1: 1})\n",
    "classifiers['random_forest']['classifier'] = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42, class_weight={0: 1, 1: 50})\n",
    "classifiers['gradient_boosting']['classifier'] = GradientBoostingClassifier(learning_rate = 0.05, n_estimators = 150, random_state=42, max_features=None, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classifiers:\n",
    "    classifiers[item]['classifier'].fit(X_train_scaled_pca, y_train)\n",
    "    train_assessment = get_measures(classifiers[item]['classifier'], X_train_scaled_pca, y_train)\n",
    "    test_assessment = get_measures(classifiers[item]['classifier'], X_test_scaled_pca, y_test)\n",
    "    print(f\"{item} AUC_train = {'{:1.3f}'.format(train_assessment[-2])} AUC_test = {'{:1.3f}'.format(train_assessment[-2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [10**c for c in range(-3, 16, 1)]\n",
    "weights = [1, 2, 5, 10, 20, 30, 40, 50, 70, 100, 120, 150, 200, 250, 300, 400, 500]\n",
    "class_weight = [{0:1, 1:x} for x in weights]\n",
    "class_weight.append('balanced')\n",
    "\n",
    "# 1 - Logistic Regression\n",
    "log_reg_param_grid = {'C': C, 'class_weight': class_weight}\n",
    "log_reg_classifier = LogisticRegression(C = 1.0, class_weight = 'balanced', random_state = 42, verbose = 1)\n",
    "log_reg_grid_search = model_grid_search(log_reg_classifier, log_reg_param_grid, X_train, y_train)\n",
    "\n",
    "with open('log_reg_grid_search.pickle', 'wb') as file:\n",
    "    pickle.dump(log_reg_grid_search, file)\n",
    "    \n",
    "log_reg_result = pd.DataFrame(log_reg_grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "log_reg_result.to_csv(\"log_reg_result.csv\", index=False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(log_reg_grid_search.best_score_))\n",
    "HTML(pd.DataFrame(log_reg_grid_search.cv_results_)[['param_C', 'param_class_weight', 'mean_train_score', 'mean_test_score']].to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 - DecisionTree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_splitter = ['best']\n",
    "tree_max_depth = [3, 4, 5, 6, 7, 8]\n",
    "# tree_class_weight = [{0:1, 1:1}, {0:1, 1:50},{0:1, 1:100},{0:1, 1:150}, {0:1, 1:200}, {0:1, 1:250}, {0:1, 1:300}, 'balanced']\n",
    "tree_class_weight = class_weight\n",
    "\n",
    "tree_param_grid = {'splitter':tree_splitter, 'max_depth':tree_max_depth, 'class_weight':tree_class_weight}\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42, splitter='best', max_depth=10, class_weight='balanced')\n",
    "\n",
    "tree_grid_search = model_grid_search(tree_classifier, tree_param_grid, X_train, y_train)\n",
    "\n",
    "with open('tree_grid_search.pickle', 'wb') as file:\n",
    "    pickle.dump(tree_grid_search, file)\n",
    "\n",
    "tree_result = pd.DataFrame(tree_grid_search.cv_results_)[['param_class_weight', 'param_splitter', 'param_max_depth', 'mean_train_score', 'mean_test_score']]\n",
    "tree_result.to_csv(\"tree_result.csv\", index=False, sep = ';')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 - RandomForest\n",
    "\n",
    "rf_max_depth = [3, 5, 9, 15, 25]\n",
    "rf_class_weight = [{0:1, 1:1}, {0:1, 1:50}, {0:1, 1:100}, {0:1, 1:300}, 'balanced'] \n",
    "rf_n_estimators = [10, 50, 100, 500]\n",
    "rf_param_grid = {'max_depth':rf_max_depth, 'class_weight':rf_class_weight, 'n_estimators':rf_n_estimators}\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42, class_weight='balanced')\n",
    "\n",
    "rf_grid_search = model_grid_search(rf_classifier, rf_param_grid, X_train, y_train)\n",
    "\n",
    "with open('rf_grid_search.pickle', 'wb') as file:\n",
    "    pickle.dump(rf_grid_search, file)\n",
    "\n",
    "rf_result = pd.DataFrame(rf_grid_search.cv_results_)[['param_class_weight', 'param_n_estimators', 'param_max_depth', 'mean_train_score', 'mean_test_score']]\n",
    "rf_result.to_csv(\"rf_result.csv\", index=False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_learning_rate = [0.001, 0.01, 0.1, 1., 10.]\n",
    "gb_n_estimators = [20, 50, 100, 200, 300, 700]\n",
    "gb_max_features = ['sqrt', 'log2', None]\n",
    "gb_param_grid = {'learning_rate':gb_learning_rate, 'n_estimators':gb_n_estimators, 'max_features':gb_max_features}\n",
    "gb_classifier = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 10, random_state=42, max_features=None, verbose=1)\n",
    "\n",
    "gb_grid_search = model_grid_search(gb_classifier, gb_param_grid, X_train, y_train)\n",
    "\n",
    "with open('gb_grid_search.pickle', 'wb') as file:\n",
    "    pickle.dump(gb_grid_search, file)                 \n",
    "\n",
    "gb_result = pd.DataFrame(gb_grid_search.cv_results_)[['param_learning_rate', 'param_n_estimators', 'param_max_features', 'mean_train_score', 'mean_test_score']]\n",
    "gb_result.to_csv(\"gb_result.csv\", index=False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - XGBoost\n",
    "\n",
    "import xgboost\n",
    "\n",
    "xgb_learning_rate = [0.001, 0.01, 0.1, 1.]\n",
    "xgb_n_estimators = [20, 50, 100, 200, 300, 500, 700]\n",
    "xgb_max_features = ['sqrt', 'log2', None]\n",
    "xgb_param_grid = {'learning_rate':xgb_learning_rate, 'n_estimators':xgb_n_estimators, 'max_features':xgb_max_features}\n",
    "xgb_classifier = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 10, random_state=42, max_features=None, verbose=1) \n",
    "\n",
    "xgb_grid_search = model_grid_search(xgb_classifier, xgb_param_grid, X_train, y_train)\n",
    "\n",
    "with open('xgb_grid_search.pickle', 'wb') as file:\n",
    "    pickle.dump(xgb_grid_search, file)                 \n",
    "\n",
    "xgb_result = pd.DataFrame(xgb_grid_search.cv_results_)[['param_learning_rate', 'param_n_estimators', 'param_max_features', 'mean_train_score', 'mean_test_score']]\n",
    "xgb_result.to_csv(\"xgb_result.csv\", index=False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(rf_grid_search.best_score_))\n",
    "HTML(pd.DataFrame(rf_grid_search.cv_results_)[['param_max_depth', 'param_class_weight', 'param_n_estimators', 'mean_train_score', 'mean_test_score']].to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "log_reg_C = [10**c for c in range(0, 10, 1)]\n",
    "for C in log_reg_C:\n",
    "    params = [C, weight]\n",
    "    model = LogisticRegression(C=C, class_weight=weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    models.append([params, model, get_measures(model, X_train, y_train)[7:], get_measures(model, X_test, y_test)[7:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train_scaled)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0\n",
    "explained_variance_cum = []\n",
    "for item in explained_variance:\n",
    "    ratio += item\n",
    "    explained_variance_cum.append(ratio)\n",
    "explained_variance_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 14, random_state=42)\n",
    "pca.fit(X_train_scaled)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0\n",
    "explained_variance_cum = []\n",
    "for item in explained_variance:\n",
    "    ratio += item\n",
    "    explained_variance_cum.append(ratio)\n",
    "explained_variance_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_pca = pca.transform(X_train_scaled)\n",
    "X_test_scaled_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Logistic Regression\n",
    "log_reg_C = [10**c for c in range(4, 11, 1)]\n",
    "log_reg_class_weight = [{0:1, 1:1}, {0:1, 1:50},{0:1, 1:100},{0:1, 1:150}, {0:1, 1:200}, {0:1, 1:250}, {0:1, 1:300}, 'balanced'] \n",
    "log_reg_param_grid = {'C': log_reg_C, 'class_weight': log_reg_class_weight}\n",
    "log_reg_grid_search = model_grid_search(LogisticRegression(), log_reg_param_grid, X_train_scaled_pca, y_train)\n",
    "\n",
    "with open('log_reg_grid_search_pca.pickle', 'wb') as file:\n",
    "    pickle.dump(log_reg_grid_search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(log_reg_grid_search.best_score_))\n",
    "HTML(pd.DataFrame(log_reg_grid_search.cv_results_)[['param_C', 'param_class_weight', 'mean_train_score', 'mean_test_score']].to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "scores = []\n",
    "for item in models:\n",
    "    scores.append(item[2][1])\n",
    "scores = np.reshape(scores, (15,9))\n",
    "heatmap(scores, ylabel='C', yticklabels=log_reg_C, xlabel='weight', xticklabels=[item[1] for item in log_reg_class_weight], cmap=\"viridis\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array(results.mean_test_score).reshape(6, 6)\n",
    "# plot the mean cross-validation scores\n",
    "heatmap(scores, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(values, xlabel, ylabel, xticklabels, yticklabels, cmap=None,\n",
    "            vmin=None, vmax=None, ax=None, fmt=\"%0.2f\"):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    # plot the mean cross-validation scores\n",
    "    img = ax.pcolor(values, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    img.update_scalarmappable()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(np.arange(len(xticklabels)) + .5)\n",
    "    ax.set_yticks(np.arange(len(yticklabels)) + .5)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    for p, color, value in zip(img.get_paths(), img.get_facecolors(),\n",
    "                               img.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.mean(color[:3]) > 0.5:\n",
    "            c = 'k'\n",
    "        else:\n",
    "            c = 'w'\n",
    "        ax.text(x, y, fmt % value, color=c, ha=\"center\", va=\"center\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in models:\n",
    "    print(f\"C = {item[0][0]}  weight = {item[0][1][1]}  auc_train = {item[2][1]}  auc_test = {item[3][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = []\n",
    "for C in [3**c for c in range(-15, 25, 1)]:\n",
    "    model = LogisticRegression(C=C)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append([C, get_measures(model, X_train, y_train), get_measures(model, X_test, y_test)])\n",
    "\n",
    "C = [item[0] for item in scores]\n",
    "train = [item[1] for item in scores]\n",
    "test = [item[2] for item in scores]\n",
    "df_train = pd.DataFrame(train, columns = ['TN_train', 'FN_train', 'FP_train', 'TP_train', 'accuracy_train', 'precision_train', 'recall_train', 'f1_train', 'auc_train'])\n",
    "df_test = pd.DataFrame(test, columns = ['TN_test', 'FN_test', 'FP_test', 'TP_test', 'accuracy_test', 'precision_test', 'recall_test', 'f1_test', 'auc_test'])\n",
    "df = pd.concat([pd.DataFrame(C, columns = ['C']), df_train, df_test], axis=1)\n",
    "df.to_csv(\"Linear_regression_scores.csv\", sep = ';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "xgb_scores = []\n",
    "for max_depth in [3, 4, 5, 7, 9, 11]:\n",
    "    for learning_rate in [0.01, 0.1, 0.3, 0.5, 1, 3]:\n",
    "        for n_estimators in [200, 500, 700, 1000]:\n",
    "            xgb = xgboost.XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "            xgb.fit(X_train, y_train)\n",
    "            xgb_scores.append([ [max_depth, learning_rate, n_estimators], get_measures(model, X_train, y_train), get_measures(model, X_test, y_test)])\n",
    "\n",
    "hiperparams = [item[0] for item in xgb_scores]\n",
    "train = [item[1] for item in xgb_scores]\n",
    "test = [item[2] for item in xgb_scores]\n",
    "df_params = pd.DataFrame(hiperparams, columns=['max_depth', 'learning_rate', 'n_estimators'])\n",
    "df_train = pd.DataFrame(train, columns = ['TN_train', 'FN_train', 'FP_train', 'TP_train', 'accuracy_train', 'precision_train', 'recall_train', 'f1_train', 'auc_train'])\n",
    "df_test = pd.DataFrame(test, columns = ['TN_test', 'FN_test', 'FP_test', 'TP_test', 'accuracy_test', 'precision_test', 'recall_test', 'f1_test', 'auc_test'])\n",
    "df = pd.concat([df_params, df_train, df_test], axis=1)\n",
    "df.to_csv(\"xgboost_scores.csv\", sep = ';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(model, X_train, y_train, X_test, y_test):\n",
    "    scores = {}\n",
    "    confusion_matrix_train = confusion_matrix(model.predict(X_train),y_train)\n",
    "    confusion_matrix_test = confusion_matrix(model.predict(X_test),y_test)\n",
    "    accuracy_score_train = accuracy_score(model.predict(X_train),y_train)\n",
    "    accuracy_score_test = accuracy_score(model.predict(X_test),y_test)\n",
    "    f1_score_train = f1_score(model.predict(X_train),y_train)\n",
    "    f1_score_test = f1_score(model.predict(X_test),y_test)\n",
    "\n",
    "    scores['train'] = {'TN':confusion_matrix_train[0][0], 'FP':confusion_matrix_train[0][1], \n",
    "                       'FN':confusion_matrix_train[1][0], 'TP':confusion_matrix_train[1][1],\n",
    "                        'accuracy':accuracy_score_train, 'F1_score':f1_score_train}\n",
    "\n",
    "    scores['test'] = {'TN':confusion_matrix_test[0][0], 'FP':confusion_matrix_test[0][1], \n",
    "                       'FN':confusion_matrix_test[1][0], 'TP':confusion_matrix_test[1][1],\n",
    "                        'accuracy':accuracy_score_test, 'F1_score':f1_score_test}\n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = list(X_train[y_train==1].index)\n",
    "negative = list(X_train[y_train==0].index)\n",
    "\n",
    "positive_size = 20000\n",
    "negative_size = 180000\n",
    "\n",
    "positive_random = np.random.uniform(0, len(positive), positive_size)\n",
    "positive_random = [ positive[int(x)] for x in positive_random]\n",
    "positive_random = [X_train[X_train.index == x] for x in positive_random]\n",
    "positive_random = pd.concat(positive_random)\n",
    "positive_random['y'] = 1\n",
    "\n",
    "negative_random = np.random.uniform(0, len(negative), negative_size)\n",
    "negative_random = [ negative[int(x)] for x in negative_random]\n",
    "negative_random = [X_train[X_train.index == x] for x in negative_random]\n",
    "negative_random = pd.concat(negative_random)\n",
    "negative_random['y'] = 0\n",
    "\n",
    "X_train_bootstrap = pd.concat([positive_random, negative_random])\n",
    "X_train_bootstrap = X_train_bootstrap.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "y_train_bootstrap = X_train_bootstrap['y']\n",
    "X_train_bootstrap = X_train_bootstrap.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_scaler = StandardScaler()\n",
    "bootstrap_scaler.fit(X_train_bootstrap)\n",
    "X_train_bootstrap_scaled = bootstrap_scaler.transform(X_train_bootstrap)\n",
    "X_test_bootstrap_scaled = bootstrap_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sety danych:\n",
    "\n",
    "plain = X_train, y_train, X_test, y_test\n",
    "scaled = X_train_scaled, y_train, X_test_scaled, y_test\n",
    "bootstrap = X_train_bootstrap, y_train_bootstrap, X_test, y_test\n",
    "bootrstrap_scaled = X_train_bootstrap_scaled, y_train_bootstrap, X_test_bootstrap_scaled, y_test\n",
    "\n",
    "data_sets = {'plain':plain, 'scaled':scaled, 'boot':bootstrap, 'boot_scal':bootrstrap_scaled}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model_plain(model, X_train, y_train, X_test, y_test):\n",
    "    scores = {}\n",
    "    confusion_matrix_train = confusion_matrix(model.predict(X_train),y_train)\n",
    "    confusion_matrix_test = confusion_matrix(model.predict(X_test),y_test)\n",
    "    accuracy_score_train = accuracy_score(model.predict(X_train),y_train)\n",
    "    accuracy_score_test = accuracy_score(model.predict(X_test),y_test)\n",
    "    f1_score_train = f1_score(model.predict(X_train),y_train)\n",
    "    f1_score_test = f1_score(model.predict(X_test),y_test)\n",
    "\n",
    "    scores['train'] = {'TN_train':confusion_matrix_train[0][0], 'FP_train':confusion_matrix_train[0][1], \n",
    "                       'FN_train':confusion_matrix_train[1][0], 'TP_train':confusion_matrix_train[1][1],\n",
    "                        'accuracy_train':accuracy_score_train, 'F1_score_train':f1_score_train}\n",
    "\n",
    "    scores['test'] = {'TN_test':confusion_matrix_test[0][0], 'FP_test':confusion_matrix_test[0][1], \n",
    "                       'FN_test':confusion_matrix_test[1][0], 'TP_test':confusion_matrix_test[1][1],\n",
    "                        'accuracy_test':accuracy_score_test, 'F1_score_test':f1_score_test}\n",
    "    scores['train'].update(scores['test'])\n",
    "    return scores['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna\n",
    "\n",
    "models = []\n",
    "counter = 1\n",
    "for data_set in data_sets:\n",
    "    for C_param in range(-4, 14, 2):\n",
    "        model = {}\n",
    "        model['counter'] = counter\n",
    "        model['data_set'] = data_set\n",
    "        model['model'] = LogisticRegression(C=10**C_param)\n",
    "        ds = data_sets[data_set]\n",
    "        model['model'].fit(ds[0], ds[1])\n",
    "        model['C'] = C_param\n",
    "        assessment = assess_model(model['model'], ds[0], ds[1], ds[2], ds[3])\n",
    "        model.update(assessment)\n",
    "        models.append(model)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x['train']['F1_score'] for x in models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna na bootstrapie\n",
    "log_reg_bootstrap = LogisticRegression()\n",
    "log_reg_bootstrap.fit(X_train_bootstrap, y_train_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_model(log_reg_bootstrap, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna\n",
    "log_reg = LogisticRegression()\n",
    "log_reg_scaled = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_model(log_reg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_model(log_reg_scaled, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "\n",
    "xgb_bootstrap = xgboost.XGBClassifier()\n",
    "xgb_bootstrap.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "assess_model(xgb_bootstrap, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_model(xgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "\n",
    "# xgb_bootrstrap_scaled = xgboost.XGBClassifier()\n",
    "# xgb_bootrstrap_scaled.fit(bootrstrap_scaled[0], bootrstrap_scaled[1])\n",
    "assess_model(xgb_bootrstrap_scaled, bootrstrap_scaled[0], bootrstrap_scaled[1], bootrstrap_scaled[2], bootrstrap_scaled[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
